# Regress√£o Linear com Rede Neural: Previs√£o de Tarifas de T√°xi em NY

Este projeto implementa um modelo de regress√£o com redes neurais (usando PyTorch) para prever o valor total das corridas de t√°xi em Nova York. O destaque da an√°lise √© a utiliza√ß√£o de **estratifica√ß√£o geogr√°fica** (bairros e zonas) e **segmenta√ß√£o temporal** para enriquecer as features do modelo, alcan√ßando um coeficiente de determina√ß√£o ($R^2$) de **0.9729** no conjunto de teste.

![Previs√µes vs Reais](images/result.png)
*(Sugest√£o: Adicione um print do seu gr√°fico de "Previs√µes vs. Valores Reais" a uma pasta `images` e o insira aqui)*

---

## üìã √çndice
* [Vis√£o Geral](#-vis√£o-geral)
* [Fonte de Dados](#-fonte-de-dados)
* [Metodologia](#-metodologia)
* [Resultados](#-resultados)
* [Como Executar o Projeto](#-como-executar-o-projeto)
* [Tecnologias Utilizadas](#-tecnologias-utilizadas)

---

## üéØ Vis√£o Geral
O objetivo principal √© construir um modelo preditivo robusto que estime o `total_amount` de uma corrida de t√°xi com base em suas caracter√≠sticas, como dist√¢ncia, localiza√ß√£o, hor√°rio e dura√ß√£o. A an√°lise explora como a demanda e os pre√ßos variam drasticamente entre diferentes bairros de Manhattan, Brooklyn, etc., e em diferentes hor√°rios (pico, madrugada).

## üìä Fonte de Dados
O dataset utilizado √© o **NYC Yellow Taxi Trip Data**, disponibilizado publicamente no Kaggle pela NYC Taxi & Limousine Commission.
* **Link:** https://www.kaggle.com/datasets/elemento/nyc-yellow-taxi-trip-data
* **Arquivo espec√≠fico:** `yellow_tripdata_2015-01.csv`. Foi utilizada uma amostra de 500.000 registros para o estudo, devido a limita√ß√µes de processamento no ambiente Colab.
* O shapefile das zonas de t√°xi de NYC foi obtido diretamente do site da NYC TLC.

## üõ†Ô∏è Metodologia
O projeto foi estruturado nas seguintes etapas:
1.  **An√°lise Explorat√≥ria e Limpeza de Dados:** Identifica√ß√£o e remo√ß√£o de dados inconsistentes, como corridas com dist√¢ncia ou valor nulos/negativos e coordenadas geogr√°ficas inv√°lidas.
2.  **Engenharia de Features:**
    * **Temporais:** Extra√ß√£o de hora, dia da semana e m√™s do in√≠cio da corrida.
    * **Geoespaciais:** Utiliza√ß√£o da biblioteca `GeoPandas` para realizar um *spatial join* entre as coordenadas de embarque/desembarque e o shapefile das zonas de t√°xi, criando features de bairro e zona.
3.  **Pr√©-processamento:** Normaliza√ß√£o de features num√©ricas (`StandardScaler`) e codifica√ß√£o de features categ√≥ricas (`OneHotEncoder`).
4.  **Modelagem com PyTorch:** Constru√ß√£o de uma rede neural com 4 camadas densas e fun√ß√µes de ativa√ß√£o ReLU.
5.  **Treinamento:** O modelo foi treinado por 50 √©pocas usando o otimizador Adam e a fun√ß√£o de perda MSELoss.
6.  **Avalia√ß√£o:** O desempenho foi medido no conjunto de teste com as m√©tricas MSE, RMSE e R-squared.

## üìà Resultados
O modelo final alcan√ßou os seguintes resultados no conjunto de dados de teste:
* **Mean Squared Error (MSE):** 3.44
* **Root Mean Squared Error (RMSE):** $1.86 (o erro m√©dio das previs√µes √© de aprox. $1,86)
* **R-squared (R¬≤):** **0.9729** (o modelo explica aproximadamente 97,29% da vari√¢ncia nos valores das corridas)

## üöÄ Como Executar o Projeto

**Pr√©-requisitos:**
* Python 3.8+
* Jupyter Notebook ou Jupyter Lab

**Passos:**
1.  Clone este reposit√≥rio:
    ```bash
    git clone [https://github.com/SEU-USUARIO/SEU-REPOSITORIO.git](https://github.com/SEU-USUARIO/SEU-REPOSITORIO.git)
    cd SEU-REPOSITORIO
    ```
2.  Crie e ative um ambiente virtual (recomendado):
    ```bash
    python -m venv venv
    source venv/bin/activate  # No Windows: venv\Scripts\activate
    ```
3.  Instale as depend√™ncias:
    ```bash
    pip install -r requirements.txt
    ```
4.  **Download dos Dados:**
    * Baixe o arquivo `yellow_tripdata_2015-01.csv` do link do Kaggle acima.
    * Crie uma pasta `data` dentro do projeto e coloque o arquivo `.csv` nela.
5.  Execute o notebook:
    ```bash
    jupyter notebook Projeto_1_DL_Completo.ipynb
    ```

## üíª Tecnologias Utilizadas
* Python
* Pandas & NumPy para manipula√ß√£o de dados
* Scikit-learn para pr√©-processamento
* PyTorch para o modelo de Deep Learning
* GeoPandas & Shapely para an√°lise geoespacial
* Matplotlib & Seaborn para visualiza√ß√£o
* Statsmodels para an√°lise estat√≠stica (VIF)